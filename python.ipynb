{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_iris, load_linnerud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load classification and regression datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "regression_dataset = load_linnerud()\n",
    "classification_dataset = load_iris()\n",
    "\n",
    "# Split into inputs and targets\n",
    "regression_X, regression_Y = regression_dataset.data, regression_dataset.target\n",
    "classification_X, classification_Y = classification_dataset.data, classification_dataset.target\n",
    "\n",
    "# Preprocess datasets\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "regression_X = numerical_transformer.fit_transform(regression_X)\n",
    "classification_X = numerical_transformer.fit_transform(classification_X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "regression_X_train, regression_X_test, regression_Y_train, regression_Y_test = train_test_split(regression_X, regression_Y, test_size=0.2, random_state=42)\n",
    "classification_X_train, classification_X_test, classification_Y_train, classification_Y_test = train_test_split(classification_X, classification_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_eval(my_model, library_model, X_train, X_test, Y_train, Y_test, decimal_places=5):\n",
    "    \n",
    "    # Fit models\n",
    "    my_model.fit(X_train, Y_train)\n",
    "    library_model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Predict\n",
    "    my_pred = my_model.predict(X_test)\n",
    "    library_pred = library_model.predict(X_test)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    my_mse = round(mean_squared_error(Y_test, my_pred), decimal_places)\n",
    "    library_mse = round(mean_squared_error(Y_test, library_pred), decimal_places)\n",
    "    \n",
    "    return my_mse, library_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I will focus on implementing the classical machine learning models:\n",
    "* [Linear Regression](#linear-regression)\n",
    "* [Logistic Regression](#logistic-regression)\n",
    "* [Support Vector Machine](#support-vector-machine)\n",
    "* [K-Means](#k-means)\n",
    "* [K-Nearest Neighbors](#k-nearest-neighbors)\n",
    "* [Decision Trees](#decision-trees)\n",
    "* [Random Forest](#random-forest)\n",
    "* [Naive Bayes](#naive-bayes)\n",
    "* [Principal Component Analysis](#principal-component-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LibraryLinearRegression\n",
    "\n",
    "class MyLinearRegression():\n",
    "    \n",
    "    def __init__(self, learning_rate: float, iterations: int) -> None:\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def fit(self, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "        \n",
    "        # Training examples\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # Number of training examples and input/output features\n",
    "        self.m, self.n = X.shape\n",
    "        self.o = Y.shape[1]\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self.W = np.zeros([self.n, self.o])\n",
    "        self.b = np.zeros(self.o)\n",
    "        \n",
    "        print(self.W.shape)\n",
    "        print(self.b.shape)\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            self.update_weights()\n",
    "        \n",
    "        return np.mean(np.square(self.predict(X) - Y))\n",
    "    \n",
    "    def update_weights(self):\n",
    "        \n",
    "        # Predict the output\n",
    "        Y_pred = self.predict(self.X)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        dW = 2 * (self.X.T).dot(Y_pred - self.Y) / self.m\n",
    "        db = 2 * np.mean(Y_pred - self.Y)\n",
    "        \n",
    "        # Update weights\n",
    "        self.W = self.W - self.learning_rate * dW\n",
    "        self.b = self.b - self.learning_rate * db\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return X.dot(self.W) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = MyLinearRegression(0.01, 1000)\n",
    "library_model = LibraryLinearRegression()\n",
    "my_mse, library_mse = regression_eval(\n",
    "    my_model, \n",
    "    library_model, \n",
    "    regression_X_train[:,1].reshape(-1,1),\n",
    "    regression_X_test[:,1].reshape(-1,1),\n",
    "    regression_Y_train[:,1].reshape(-1,1),\n",
    "    regression_Y_test[:,1].reshape(-1,1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.axline((0, my_model.b), slope=my_model.W[0], color='red', label='My Model', linestyle='dotted')\n",
    "ax.axline((0, library_model.intercept_), slope=library_model.coef_[0], color='blue', label='Library Model', linestyle='dotted')\n",
    "ax.scatter(regression_X[:,1], regression_Y[:,1], color='black')\n",
    "ax.legend([f'My Model | MSE={my_mse}', f'Library Model | MSE={library_mse}'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3,)\n",
      "My Model MSE: 1937.36119\n",
      "Library Model MSE: 239.15367\n"
     ]
    }
   ],
   "source": [
    "my_model = MyLinearRegression(0.001, 10000)\n",
    "library_model = LibraryLinearRegression()\n",
    "my_mse, library_mse = regression_eval(\n",
    "    my_model, \n",
    "    library_model, \n",
    "    regression_X_train,\n",
    "    regression_X_test,\n",
    "    regression_Y_train,\n",
    "    regression_Y_test)\n",
    "\n",
    "print(f'My Model MSE: {my_mse}')\n",
    "print(f'Library Model MSE: {library_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
